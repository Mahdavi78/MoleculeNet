{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727d731d-1961-4907-91c6-0ae29edd34a8",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629934a7-471e-44ec-b9ca-dd2b67dd04f7",
   "metadata": {},
   "source": [
    "# Tokenizing smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b486ba-ae31-444a-acb1-a34595d22257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from Preprocess.utils import SMILESTokenizerBuilder, RawDataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae180f9-fd25-49a5-9093-2c773a5f6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"qm9.csv\"\n",
    "\n",
    "# Initialize the data loader with qm9.csv\n",
    "loader = RawDataLoader(file_name, smiles_column=\"smiles\")\n",
    "\n",
    "# Create a tokenizer with initial vocabulary of basic elements\n",
    "initial_vocab = [\"C\", \"N\", \"O\"]\n",
    "tokenizer = SMILESTokenizerBuilder(vocab_list=initial_vocab)\n",
    "\n",
    "# Get unique tokens from all SMILES\n",
    "unique_tokens = tokenizer.tokenize_with_vocab(loader.data, \"smiles\")\n",
    "tokenizer.build_vocab_mappings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042d2470-a7af-4da9-8231-1960b8d0f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting vocabulary after processing all SMILES:\n",
      "['<SOS>', 'C', 'F', 'H', 'N', 'O', '#', '(', ')', '+', '-', '=', '[', ']', '1', '2', '3', '4', '5', '<EOS>', '<PAD>']\n",
      "\n",
      "Token's id\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 60, 'C': 10, 'F': 11, 'H': 12, 'N': 13, 'O': 14, '#': 30, '(': 31, ')': 32, '+': 33, '-': 34, '=': 35, '[': 36, ']': 37, '1': 40, '2': 41, '3': 42, '4': 43, '5': 44}\n",
      "\n",
      "Token statistics\n",
      "Number of unique tokens found: 21\n",
      "Tokens Frequency : Counter({'C': 846556, '1': 270020, 'O': 187997, 'N': 139764, '(': 126532, ')': 126532, '2': 121675, '=': 106335, '#': 37027, '3': 34756, '[': 9918, ']': 9918, 'H': 8247, '4': 5186, 'F': 3314, '-': 1808, '+': 1705, '5': 242})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the resulting vocabulary\n",
    "\n",
    "print(\"Resulting vocabulary after processing all SMILES:\")\n",
    "print(unique_tokens)\n",
    "\n",
    "print(\"\\nToken's id\")\n",
    "print(tokenizer.vocab_to_idx)\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nToken statistics\")\n",
    "print(f\"Number of unique tokens found: {len(unique_tokens)}\")\n",
    "print(f\"Tokens Frequency : {tokenizer.token_counts}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stats = tokenizer.token_counts\n",
    "sorted_items = sorted(stats.items(), key=lambda x: x[1], reverse=True)\n",
    "tokens, counts = zip(*sorted_items)\n",
    "\n",
    "plt.bar(tokens, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4a1f3c1-9ebc-43d3-ba57-25bea487c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([133885, 40])\n",
      "\n",
      "Sequence with least padding (index 24869):\n",
      "Sequence: [1, 10, 40, 31, 35, 14, 32, 36, 13, 12, 37, 10, 31, 35, 14, 32, 36, 13, 12, 37, 10, 31, 35, 14, 32, 36, 13, 12, 37, 40, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Number of padding tokens: 9\n",
      "Original SMILES: c1(=O)[nH]c(=O)[nH]c(=O)[nH]1\n",
      "\n",
      "Top 3 sequences with least padding:\n",
      "\n",
      "Index 24869:\n",
      "Sequence: [1, 10, 40, 31, 35, 14, 32, 36, 13, 12, 37, 10, 31, 35, 14, 32, 36, 13, 12, 37, 10, 31, 35, 14, 32, 36, 13, 12, 37, 40, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Padding tokens: 9\n",
      "Original SMILES: c1(=O)[nH]c(=O)[nH]c(=O)[nH]1\n",
      "\n",
      "Index 54383:\n",
      "Sequence: [1, 10, 10, 40, 41, 10, 10, 31, 10, 40, 32, 31, 36, 13, 12, 41, 33, 37, 41, 32, 10, 31, 36, 14, 34, 37, 32, 35, 14, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Padding tokens: 10\n",
      "Original SMILES: CC12CC(C1)([NH2+]2)C([O-])=O\n",
      "\n",
      "Index 54386:\n",
      "Sequence: [1, 36, 13, 12, 42, 33, 37, 10, 40, 41, 10, 10, 31, 10, 40, 32, 31, 10, 41, 32, 10, 31, 36, 14, 34, 37, 32, 35, 14, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Padding tokens: 10\n",
      "Original SMILES: [NH3+]C12CC(C1)(C2)C([O-])=O\n",
      "\n",
      "Index 54548:\n",
      "Sequence: [1, 36, 14, 34, 37, 10, 31, 35, 14, 32, 10, 40, 41, 10, 10, 42, 10, 31, 36, 13, 12, 41, 33, 37, 40, 32, 10, 41, 42, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Padding tokens: 10\n",
      "Original SMILES: [O-]C(=O)C12CC3C([NH2+]1)C23\n",
      "\n",
      "Index 24953:\n",
      "Sequence: [1, 10, 40, 36, 13, 12, 37, 10, 41, 10, 31, 13, 40, 32, 36, 13, 12, 37, 10, 31, 35, 14, 32, 36, 13, 12, 37, 41, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Padding tokens: 11\n",
      "Original SMILES: c1[nH]c2c(n1)[nH]c(=O)[nH]2\n"
     ]
    }
   ],
   "source": [
    "seq_len = 40\n",
    "smiles_tensor = tokenizer.encode_to_tensor(loader.data, seq_len)\n",
    "print(f\"Tensor shape: {smiles_tensor.shape}\")\n",
    "\n",
    "# Calculate number of zeros (padding) in each sequence\n",
    "padding_counts = (smiles_tensor == 0).sum(dim=1)\n",
    "\n",
    "# Find the index of the sequence with minimum padding\n",
    "min_padding_idx = padding_counts.argmin().item()\n",
    "\n",
    "# Get the sequence with least padding\n",
    "least_padded_seq = smiles_tensor[min_padding_idx]\n",
    "\n",
    "print(f\"\\nSequence with least padding (index {min_padding_idx}):\")\n",
    "print(f\"Sequence: {least_padded_seq.tolist()}\")\n",
    "print(f\"Number of padding tokens: {padding_counts[min_padding_idx].item()}\")\n",
    "print(f\"Original SMILES: {loader.data.iloc[min_padding_idx]['smiles']}\")\n",
    "\n",
    "# Optional: Show top 5 sequences with least padding\n",
    "print(\"\\nTop 3 sequences with least padding:\")\n",
    "top_3_indices = padding_counts.argsort()[:3]\n",
    "for idx in top_5_indices:\n",
    "    idx_int = idx.item()  # Convert tensor to integer\n",
    "    seq = smiles_tensor[idx_int]\n",
    "    print(f\"\\nIndex {idx_int}:\")\n",
    "    print(f\"Sequence: {seq.tolist()}\")\n",
    "    print(f\"Padding tokens: {padding_counts[idx_int].item()}\")\n",
    "    print(f\"Original SMILES: {loader.data.iloc[idx_int]['smiles']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a63397-cd34-46e5-8aff-c30d9c92bf08",
   "metadata": {},
   "source": [
    "# Getting Target's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d618820b-7701-4af4-981f-fa5d08eca2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([133885])\n",
      "tensor(-119.0479)\n"
     ]
    }
   ],
   "source": [
    "Y = torch.tensor(loader.data['u298'].values, dtype=torch.float32)\n",
    "print(Y.shape)\n",
    "print(Y[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7023f62c-b528-4fa8-b871-7e97ebe1cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y tensor statistics:\n",
      "Shape: torch.Size([133885])\n",
      "Min value: -714.5602\n",
      "Max value: -40.4761\n",
      "Mean value: -411.5355\n",
      "Median value: -417.8574\n",
      "Standard deviation: 40.0600\n",
      "\n",
      "Value distribution:\n",
      "Range -714.56 to -647.15: 2 values\n",
      "Range -647.15 to -579.74: 115 values\n",
      "Range -579.74 to -512.33: 628 values\n",
      "Range -512.33 to -444.93: 22465 values\n",
      "Range -444.93 to -377.52: 90693 values\n",
      "Range -377.52 to -310.11: 18313 values\n",
      "Range -310.11 to -242.70: 1492 values\n",
      "Range -242.70 to -175.29: 150 values\n",
      "Range -175.29 to -107.88: 21 values\n",
      "Range -107.88 to -40.48: 6 values\n",
      "\n",
      "Sample values (first 5):\n",
      "[-40.4760627746582, -56.52302551269531, -76.40187072753906, -77.30552673339844, -93.40937042236328]\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics\n",
    "print(\"Y tensor statistics:\")\n",
    "print(f\"Shape: {Y.shape}\")\n",
    "print(f\"Min value: {Y.min().item():.4f}\")\n",
    "print(f\"Max value: {Y.max().item():.4f}\")\n",
    "print(f\"Mean value: {Y.float().mean().item():.4f}\")\n",
    "print(f\"Median value: {Y.float().median().item():.4f}\")\n",
    "print(f\"Standard deviation: {Y.float().std().item():.4f}\")\n",
    "\n",
    "# Optional: Show distribution in bins\n",
    "print(\"\\nValue distribution:\")\n",
    "hist = torch.histc(Y.float(), bins=10)\n",
    "bin_edges = torch.linspace(Y.min(), Y.max(), 11)\n",
    "for i in range(10):\n",
    "    print(f\"Range {bin_edges[i]:.2f} to {bin_edges[i+1]:.2f}: {hist[i].item():.0f} values\")\n",
    "\n",
    "# Optional: Show some sample values\n",
    "print(\"\\nSample values (first 5):\")\n",
    "print(Y[:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53203c5e-b473-4d83-8cc0-3d274b9919bf",
   "metadata": {},
   "source": [
    "# Creating Model\n",
    "Model is consists of a Transformer_encoder part to reach latent space and then an MLP to do the Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4de81fb9-b747-4928-877b-758609fb0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.transformer_encoder import TransformerEncoder\n",
    "from Model.mlp import MLP\n",
    "from Model.combined_model import CombinedModel\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc24a3f9-e244-4484-a8b7-09475f3a0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "transformer = TransformerEncoder(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=2,\n",
    "    dim_feedforward=512,\n",
    "    dropout=0.1,\n",
    "    max_seq_length=seq_len,\n",
    "    padding_token=0\n",
    ")\n",
    "\n",
    "mlp = MLP(\n",
    "    input_dim=128,\n",
    "    output_dim=1,\n",
    "    dims=[256,128,64,32,8,1],\n",
    "    activations=['leaky_relu', 'leaky_relu', 'tanh','tanh', 'tanh','']\n",
    ")\n",
    "\n",
    "model = CombinedModel(transformer , mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d37fcbec-bbdc-4379-b344-766e9dbf9505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 480,883\n",
      "\n",
      "Parameters by layer:\n",
      "transformer.token_embedding.weight: 7,808 parameters\n",
      "transformer.transformer_encoder.layers.0.self_attn.in_proj_weight: 49,152 parameters\n",
      "transformer.transformer_encoder.layers.0.self_attn.in_proj_bias: 384 parameters\n",
      "transformer.transformer_encoder.layers.0.self_attn.out_proj.weight: 16,384 parameters\n",
      "transformer.transformer_encoder.layers.0.self_attn.out_proj.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.0.linear1.weight: 65,536 parameters\n",
      "transformer.transformer_encoder.layers.0.linear1.bias: 512 parameters\n",
      "transformer.transformer_encoder.layers.0.linear2.weight: 65,536 parameters\n",
      "transformer.transformer_encoder.layers.0.linear2.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.0.norm1.weight: 128 parameters\n",
      "transformer.transformer_encoder.layers.0.norm1.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.0.norm2.weight: 128 parameters\n",
      "transformer.transformer_encoder.layers.0.norm2.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.1.self_attn.in_proj_weight: 49,152 parameters\n",
      "transformer.transformer_encoder.layers.1.self_attn.in_proj_bias: 384 parameters\n",
      "transformer.transformer_encoder.layers.1.self_attn.out_proj.weight: 16,384 parameters\n",
      "transformer.transformer_encoder.layers.1.self_attn.out_proj.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.1.linear1.weight: 65,536 parameters\n",
      "transformer.transformer_encoder.layers.1.linear1.bias: 512 parameters\n",
      "transformer.transformer_encoder.layers.1.linear2.weight: 65,536 parameters\n",
      "transformer.transformer_encoder.layers.1.linear2.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.1.norm1.weight: 128 parameters\n",
      "transformer.transformer_encoder.layers.1.norm1.bias: 128 parameters\n",
      "transformer.transformer_encoder.layers.1.norm2.weight: 128 parameters\n",
      "transformer.transformer_encoder.layers.1.norm2.bias: 128 parameters\n",
      "mlp.model.0.weight: 32,768 parameters\n",
      "mlp.model.0.bias: 256 parameters\n",
      "mlp.model.2.weight: 32,768 parameters\n",
      "mlp.model.2.bias: 128 parameters\n",
      "mlp.model.4.weight: 8,192 parameters\n",
      "mlp.model.4.bias: 64 parameters\n",
      "mlp.model.6.weight: 2,048 parameters\n",
      "mlp.model.6.bias: 32 parameters\n",
      "mlp.model.8.weight: 256 parameters\n",
      "mlp.model.8.bias: 8 parameters\n",
      "mlp.model.10.weight: 8 parameters\n",
      "mlp.model.10.bias: 1 parameters\n",
      "mlp.model.11.weight: 1 parameters\n",
      "mlp.model.11.bias: 1 parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Count total parameters\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "# Optional: Print parameters by layer\n",
    "print(\"\\nParameters by layer:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.numel():,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9f5ae1ea-a7af-4df8-a779-ba5df1376be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from Model.utils import create_data_loaders\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "226dc502-7311-406b-abdc-932310054bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = smiles_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6166a-678a-4b9c-9165-7cd5c6eb5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    p=0.5,  # Use p% of data\n",
    "    split_ratios=[0.1, 0.18, 0.72],  # [test, val, train] ratios\n",
    "    batch_size=160\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcb89d-eaa4-46fc-9139-1aa49b789caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from Model.trainer import Trainer\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()  # For energy task\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6dc13-4761-4e1a-a598-16cfe10ff1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c42d2-b886-455e-9dda-9f2952d24da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Batch: 0/302 Loss: 166087.5781\n",
      "Epoch: 1/10 Batch: 20/302 Loss: 173412.2656\n",
      "Epoch: 1/10 Batch: 40/302 Loss: 170893.1875\n",
      "Epoch: 1/10 Batch: 60/302 Loss: 164825.5625\n",
      "Epoch: 1/10 Batch: 80/302 Loss: 169438.2812\n",
      "Epoch: 1/10 Batch: 100/302 Loss: 166745.2031\n",
      "Epoch: 1/10 Batch: 120/302 Loss: 172219.7812\n",
      "Epoch: 1/10 Batch: 140/302 Loss: 156341.7344\n",
      "Epoch: 1/10 Batch: 160/302 Loss: 163146.0469\n",
      "Epoch: 1/10 Batch: 180/302 Loss: 166608.6406\n",
      "Epoch: 1/10 Batch: 200/302 Loss: 167216.2031\n",
      "Epoch: 1/10 Batch: 220/302 Loss: 165062.5000\n",
      "Epoch: 1/10 Batch: 240/302 Loss: 172022.0938\n",
      "Epoch: 1/10 Batch: 260/302 Loss: 173457.7188\n",
      "Epoch: 1/10 Batch: 280/302 Loss: 161078.1562\n",
      "Epoch: 1/10 Batch: 300/302 Loss: 170250.3750\n",
      "Epoch: 1/10 Train Loss: 166754.3401 Time: 54.97s\n",
      "Epoch: 2/10 Batch: 0/302 Loss: 174126.2500\n",
      "Epoch: 2/10 Batch: 20/302 Loss: 160370.4531\n",
      "Epoch: 2/10 Batch: 40/302 Loss: 163518.5625\n",
      "Epoch: 2/10 Batch: 60/302 Loss: 170077.3125\n",
      "Epoch: 2/10 Batch: 80/302 Loss: 163266.2500\n",
      "Epoch: 2/10 Batch: 100/302 Loss: 167894.9844\n",
      "Epoch: 2/10 Batch: 120/302 Loss: 164035.9375\n",
      "Epoch: 2/10 Batch: 140/302 Loss: 174684.1719\n",
      "Epoch: 2/10 Batch: 160/302 Loss: 156408.7812\n",
      "Epoch: 2/10 Batch: 180/302 Loss: 150770.5000\n",
      "Epoch: 2/10 Batch: 200/302 Loss: 159272.1562\n",
      "Epoch: 2/10 Batch: 220/302 Loss: 172133.4531\n",
      "Epoch: 2/10 Batch: 240/302 Loss: 163104.9219\n",
      "Epoch: 2/10 Batch: 260/302 Loss: 167182.8438\n",
      "Epoch: 2/10 Batch: 280/302 Loss: 157635.2969\n",
      "Epoch: 2/10 Batch: 300/302 Loss: 162423.2188\n",
      "Epoch: 2/10 Train Loss: 163032.5883 Time: 55.01s\n",
      "Epoch: 3/10 Batch: 0/302 Loss: 165714.0938\n",
      "Epoch: 3/10 Batch: 20/302 Loss: 165354.0156\n",
      "Epoch: 3/10 Batch: 40/302 Loss: 166210.0156\n",
      "Epoch: 3/10 Batch: 60/302 Loss: 165880.0625\n",
      "Epoch: 3/10 Batch: 80/302 Loss: 152576.5625\n",
      "Epoch: 3/10 Batch: 100/302 Loss: 165730.4688\n",
      "Epoch: 3/10 Batch: 120/302 Loss: 152557.4219\n",
      "Epoch: 3/10 Batch: 140/302 Loss: 157345.2344\n",
      "Epoch: 3/10 Batch: 160/302 Loss: 152496.8906\n",
      "Epoch: 3/10 Batch: 180/302 Loss: 157186.2188\n",
      "Epoch: 3/10 Batch: 200/302 Loss: 150630.1094\n",
      "Epoch: 3/10 Batch: 220/302 Loss: 149416.6719\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=10,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e6785-92c7-41ea-8ddc-4e325e7aecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can evaluate on validation set if needed\n",
    "val_loss = trainer.evaluate(val_loader)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4527668-c590-4bdc-a44e-cde3aef64109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6ec6f-7f4d-4ae1-b363-5803805e9088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
